name: "Publish Custom Collector Lambda layer"

on:
  workflow_dispatch:
    inputs:
      architecture:
        description: 'Architecture of the layer to be published'
        required: true
        type: choice
        options:
          - all
          - amd64
          - arm64
        default: all
      aws-region:
        description: 'AWS Region(s) where layer will be published'
        required: true
        type: choice
        options:
          - all
          - ca-west-1
          - eu-central-1
          - eu-central-2
          - eu-north-1
          - eu-south-1
          - eu-south-2
          - eu-west-1
          - eu-west-2
          - eu-west-3
          - us-east-1
          - us-east-2
          - us-west-2
        default: all
      role-arn:
        description: 'AWS IAM Role ARN to be assumed for publishing layer'
        required: false
        type: string
      layer-version:
        description: 'Layer version to be appended into the layer name'
        required: false
        type: string
      distribution:
        description: 'Select a predefined set of components or choose custom'
        required: false
        type: choice
        default: 'default'
        options:
          - default
          - minimal
          - clickhouse
          - clickhouse-otlphttp
          - full
          - custom
      build-tags:
        description: 'Custom build tags (only used if distribution is set to custom)'
        required: false
        type: string
      upstream-repo:
        description: 'Upstream OpenTelemetry Lambda repository'
        required: false
        type: string
        default: 'open-telemetry/opentelemetry-lambda'
      upstream-ref:
        description: 'Upstream Git ref (branch, tag, commit SHA)'
        required: false
        type: string
        default: 'main'


# Add permissions required to match layer-publish.yml
permissions:
  id-token: write
  contents: read

jobs:
  prepare-build-jobs:
    runs-on: ubuntu-latest
    outputs:
      build_jobs: ${{ steps.prepare-build-jobs.outputs.build_jobs }}
    steps:
      - id: prepare-build-jobs
        name: Prepare Build Jobs
        run: |
          architectures=''
          if [ "${{ github.event.inputs.architecture }}" == 'all' ]; then
            architectures='["amd64", "arm64"]'
          else
            architectures='["${{ github.event.inputs.architecture }}"]'
          fi
          echo "build_jobs={\"architecture\": ${architectures}}" | tr -d '[:space:]' >> $GITHUB_OUTPUT

  build-layer:
    needs: prepare-build-jobs
    runs-on: ubuntu-latest
    strategy:
      matrix: ${{ fromJSON(needs.prepare-build-jobs.outputs.build_jobs) }}
    steps:
      - name: Checkout Upstream Repo
        uses: actions/checkout@v4
        with:
          repository: ${{ inputs.upstream-repo }}
          ref: ${{ inputs.upstream-ref }}
          path: upstream # Checkout upstream to a specific directory

      - name: Checkout Customizations Repo (This Repo)
        uses: actions/checkout@v4
        with:
          path: custom # Checkout this repo to another directory

      - name: Overlay Custom Files
        run: |
          echo "Overlaying custom components..."
          # Copy everything from custom/components/ into upstream/
          if [ -d "custom/components" ]; then
            cp -r custom/components/* upstream/
            echo "Copied files from custom/components."
          else
            echo "No custom/components directory found to overlay."
          fi
          # List what was copied for debugging
          find upstream/collector/lambdacomponents -type f | grep -v '\.go$' || true

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '~1.21.9'

      - name: Fix Go Module Dependencies
        working-directory: ./upstream/collector
        run: |
          # Detect the OpenTelemetry version from the upstream go.mod
          echo "Detecting OpenTelemetry version from upstream go.mod..."
          # Try to extract OTEL version from go.mod using grep and sed
          OTEL_VERSION=$(grep -E "go.opentelemetry.io/collector " go.mod | sed -E 's/.*v([0-9]+\.[0-9]+\.[0-9]+).*/v\1/')
          
          # Check if we found a version
          if [ -z "$OTEL_VERSION" ]; then
            # Try alternate pattern with require syntax
            OTEL_VERSION=$(grep -E "require go.opentelemetry.io/collector " go.mod | sed -E 's/.*v([0-9]+\.[0-9]+\.[0-9]+).*/v\1/')
          fi
          
          # If still not found, fall back to a default version
          if [ -z "$OTEL_VERSION" ]; then
            echo "Could not detect OTEL version from go.mod, using default v0.122.1"
            OTEL_VERSION="v0.122.1"
          fi
          
          echo "Using OpenTelemetry version: $OTEL_VERSION"
          
          # Instead of directly editing go.mod, use go get to ensure proper dependency resolution
          echo "Installing OpenTelemetry modules with consistent versions..."
          
          # Initialize dependency list
          OTEL_DEPS=(
            "go.opentelemetry.io/collector@$OTEL_VERSION"
            "go.opentelemetry.io/collector/exporter@$OTEL_VERSION"
            "go.opentelemetry.io/collector/processor@$OTEL_VERSION"
            "go.opentelemetry.io/collector/receiver@$OTEL_VERSION"
            "go.opentelemetry.io/collector/extension@$OTEL_VERSION"
            "go.opentelemetry.io/collector/connector@$OTEL_VERSION"
            "go.opentelemetry.io/collector/pdata@v1.28.1"
            "go.opentelemetry.io/collector/consumer@v1.28.1"
          )
          
          # Install dependencies in the main module
          echo "Installing dependencies in collector module..."
          for dep in "${OTEL_DEPS[@]}"; do
            echo "Installing $dep"
            go get "$dep"
          done
          
          # Also install specific test packages that might cause issues
          go get go.opentelemetry.io/collector/component/componenttest@$OTEL_VERSION
          go get go.opentelemetry.io/collector/consumer/consumertest@$OTEL_VERSION
          go get go.opentelemetry.io/collector/pdata/testdata@$OTEL_VERSION
          
          # Remove debugexporter usage if it causes problems
          if grep -q "debugexporter" lambdacomponents/exporter/debug.go 2>/dev/null; then
            echo "Found debug exporter usage, handling potential incompatibility..."
            # Check if the problematic package exists
            if ! go list -m go.opentelemetry.io/collector/exporter/internal/requesttest &>/dev/null; then
              echo "Warning: Requesttest package not found - will modify debug.go if present"
              # If the file exists, comment out the problematic code
              if [ -f "lambdacomponents/exporter/debug.go" ]; then
                echo "Disabling debug exporter in lambdacomponents/exporter/debug.go"
                sed -i.bak 's|"go.opentelemetry.io/collector/exporter/debugexporter"|// "go.opentelemetry.io/collector/exporter/debugexporter"|g' lambdacomponents/exporter/debug.go
                sed -i.bak 's|return debugexporter.NewFactory()|// Debug exporter disabled due to compatibility issue\n\t\treturn nil|g' lambdacomponents/exporter/debug.go
              fi
            fi
          fi
          
          # Update the lambdacomponents go.mod if it exists
          if [ -f "./lambdacomponents/go.mod" ]; then
            echo "Updating lambdacomponents module..."
            cd ./lambdacomponents
            
            # Install dependencies in the lambdacomponents module
            for dep in "${OTEL_DEPS[@]}"; do
              echo "Installing $dep in lambdacomponents"
              go get "$dep"
            done
            cd ..
          fi

      - name: Tidy Go Modules (Collector)
        working-directory: ./upstream/collector
        run: go mod tidy

      - name: Tidy Go Modules (LambdaComponents)
        # Run only if lambdacomponents has its own go.mod
        if: ${{ hashFiles('upstream/collector/lambdacomponents/go.mod') != '' }}
        working-directory: ./upstream/collector/lambdacomponents
        run: go mod tidy

      - name: Build Collector
        working-directory: ./upstream # Run make from the upstream root
        run: |
          # Initialize variables
          BUILDTAGS=""
          DISTRIBUTION="${{ inputs.distribution }}"
          CUSTOM_TAGS="${{ inputs.build-tags }}"

          # Determine BUILDTAGS using a case statement
          case "$DISTRIBUTION" in
            minimal)
              BUILDTAGS="lambdacomponents.custom,lambdacomponents.receiver.otlp,lambdacomponents.processor.batch"
              ;;
            clickhouse)
              # Ensure your custom clickhouse tag is included
              BUILDTAGS="lambdacomponents.custom,lambdacomponents.receiver.otlp,lambdacomponents.processor.batch,lambdacomponents.exporter.clickhouse"
              ;;
            clickhouse-otlphttp)
              BUILDTAGS="lambdacomponents.custom,lambdacomponents.receiver.otlp,lambdacomponents.processor.batch,lambdacomponents.exporter.clickhouse,lambdacomponents.exporter.otlphttp"
              ;;
            full)
              # Requires 'lambdacomponents.custom' to opt-in, and 'lambdacomponents.all' to include everything defined under the custom build tag
              BUILDTAGS="lambdacomponents.custom,lambdacomponents.all"
              ;;
            custom)
              if [[ -n "$CUSTOM_TAGS" ]]; then
                BUILDTAGS="$CUSTOM_TAGS"
                # Ensure lambdacomponents.custom is present if custom tags are provided
                if [[ "$BUILDTAGS" != *"lambdacomponents.custom"* ]]; then
                   BUILDTAGS="lambdacomponents.custom,$BUILDTAGS"
                fi
              else
                # If distribution is custom but no tags provided, default to just the custom tag.
                BUILDTAGS="lambdacomponents.custom"
              fi
              ;;
            default | *) # Handle 'default' or any unexpected value
              BUILDTAGS="" # Ensure it's empty for the default build
              ;;
          esac

          echo "Distribution selected: $DISTRIBUTION"
          echo "Build tags determined: $BUILDTAGS"
          # Run make from within the checked-out upstream collector directory
          make -C collector package GOARCH=${{ matrix.architecture }} BUILDTAGS=$BUILDTAGS

      - name: Upload Collector Artifact
        uses: actions/upload-artifact@v4
        with:
          name: opentelemetry-collector-layer-${{ matrix.architecture }}.zip
          # Path is relative to the GITHUB_WORKSPACE, which contains the upstream checkout
          path: ${{ github.workspace }}/upstream/collector/build/opentelemetry-collector-layer-${{ matrix.architecture }}.zip

  prepare-release-jobs:
    needs: build-layer
    runs-on: ubuntu-latest
    outputs:
      release_jobs: ${{ steps.prepare-release-jobs.outputs.release_jobs }}
      collector-version: ${{ steps.collector-version.outputs.version }}
    steps:
      # Checkout upstream again to read VERSION file
      - name: Checkout Upstream Repo for VERSION file
        uses: actions/checkout@v4
        with:
          repository: ${{ inputs.upstream-repo }}
          ref: ${{ inputs.upstream-ref }}
          path: upstream
          fetch-depth: 1

      - id: prepare-release-jobs
        name: Prepare Release Jobs
        run: |
          architectures=''
          if [ "${{ github.event.inputs.architecture }}" == 'all' ]; then
            architectures='["amd64", "arm64"]'
          else
            architectures='["${{ github.event.inputs.architecture }}"]'
          fi
          aws_regions=''
          if [ "${{ github.event.inputs.aws-region }}" == 'all' ]; then
            aws_regions='["ca-west-1", "eu-central-1", "eu-central-2", "eu-north-1", "eu-south-1", "eu-south-2", "eu-west-1", "eu-west-2", "eu-west-3", "us-east-1", "us-east-2", "us-west-2"]'
          else
            aws_regions='["${{ github.event.inputs.aws-region }}"]'
          fi
          echo "release_jobs={\"architecture\": ${architectures}, \"aws_region\": ${aws_regions}}" | tr -d '[:space:]' >> $GITHUB_OUTPUT

      - name: Read collector version from Upstream
        id: collector-version
        working-directory: ./upstream # Read from the checked-out upstream repo
        run: |
          if [ -f "./collector/VERSION" ]; then
            COLLECTOR_VERSION=$(cat ./collector/VERSION)
            echo "Found upstream VERSION file: $COLLECTOR_VERSION"
          else
            echo "Upstream VERSION file not found, using fallback version"
            COLLECTOR_VERSION="v0.119.0" # Fallback
          fi
          echo "version=$COLLECTOR_VERSION" >> $GITHUB_OUTPUT
          echo "Collector version: $COLLECTOR_VERSION"

  release-layer:
    # This refers to the reusable workflow within THIS repository
    uses: ./.github/workflows/custom-layer-publish.yml
    needs: prepare-release-jobs
    strategy:
      matrix: ${{ fromJSON(needs.prepare-release-jobs.outputs.release_jobs) }}
    with:
      artifact-name: opentelemetry-collector-layer-${{ matrix.architecture }}.zip
      layer-name: opentelemetry-collector # Consider customizing this name
      architecture: ${{ matrix.architecture }}
      runtimes: "nodejs18.x nodejs20.x nodejs22.x java17 java21 python3.9 python3.10 python3.11 python3.12 python3.13 dotnet6 dotnet8 provided.al2 provided.al2023"
      release-group: prod # Or make configurable
      aws_region: ${{ matrix.aws_region }}
      role-arn: ${{ github.event.inputs.role-arn }}
      layer-version: ${{ github.event.inputs.layer-version }}
      distribution: ${{ github.event.inputs.distribution }}
      collector-version: ${{ needs.prepare-release-jobs.outputs.collector-version }}
    secrets: inherit
